#!/usr/bin/env python3
"""
Integration Cache Service (–ø–æ—Ä—Ç 8020)

–¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∫—ç—à –º–∞—Ç—Ä–∏—Ü—ã –≤–∫–ª—é—á—ë–Ω–Ω–æ—Å—Ç–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–π –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ 
–∏–∑ call-—Å–µ—Ä–≤–∏—Å–æ–≤ (dial, bridge, hangup, download).

–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:
- In-memory –∫—ç—à: enterprise_number ‚Üí {retailcrm: bool, amocrm: bool, ...}
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π refresh –∫–∞–∂–¥—ã–µ 180-300 —Å–µ–∫
- LISTEN/NOTIFY –¥–ª—è –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–π –∏–Ω–≤–∞–ª–∏–¥–∞—Ü–∏–∏
- API –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–π
- –ú–µ—Ç—Ä–∏–∫–∏ hit/miss, latency
"""

import asyncio
import asyncpg
import json
import logging
import os
import time
import random
from datetime import datetime, timedelta
from typing import Dict, Optional, Set, Any
from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/integration_cache.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
REFRESH_INTERVAL_BASE = 240  # 4 –º–∏–Ω—É—Ç—ã
REFRESH_JITTER_MAX = 60      # ¬±60 —Å–µ–∫ –¥–∂–∏—Ç—Ç–µ—Ä
TTL_SECONDS = 90             # TTL –∑–∞–ø–∏—Å–∏ –≤ –∫—ç—à–µ
CACHE_CLEANUP_INTERVAL = 30  # –û—á–∏—Å—Ç–∫–∞ –ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π

# FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI(title="Integration Cache Service", version="1.0.0")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
pg_pool: Optional[asyncpg.Pool] = None
integration_cache: Dict[str, Dict[str, Any]] = {}
cache_stats = {
    "hits": 0,
    "misses": 0,
    "refreshes": 0,
    "cache_size": 0,
    "last_full_refresh": None,
    "total_requests": 0
}

class CacheEntry:
    def __init__(self, data: Dict[str, bool]):
        self.data = data
        self.created_at = time.time()
        self.expires_at = time.time() + TTL_SECONDS
    
    def is_expired(self) -> bool:
        return time.time() > self.expires_at
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "integrations": self.data,
            "created_at": self.created_at,
            "expires_at": self.expires_at,
            "age_seconds": time.time() - self.created_at
        }

async def init_database():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î"""
    global pg_pool
    try:
        password = os.environ.get('DB_PASSWORD', 'r/Yskqh/ZbZuvjb2b3ahfg==')
        pg_pool = await asyncpg.create_pool(
            host='localhost',
            port=5432,
            user='postgres',
            password=password,
            database='postgres',
            min_size=2,
            max_size=10,
            timeout=5
        )
        logger.info("‚úÖ Database connection pool created")
    except Exception as e:
        logger.error(f"‚ùå Failed to connect to database: {e}")
        raise

async def load_integration_matrix() -> Dict[str, Dict[str, bool]]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–∞—Ç—Ä–∏—Ü—É –≤–∫–ª—é—á—ë–Ω–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–π –∏–∑ –ë–î"""
    if not pg_pool:
        return {}
    
    try:
        async with pg_pool.acquire() as conn:
            query = """
            SELECT number, integrations_config 
            FROM enterprises 
            WHERE active = true AND integrations_config IS NOT NULL
            """
            rows = await conn.fetch(query)
            
            matrix = {}
            for row in rows:
                enterprise_number = row['number']
                integrations_config = row['integrations_config']
                
                logger.info(f"üìã Processing enterprise {enterprise_number}, config type: {type(integrations_config)}")
                
                # –ü–∞—Ä—Å–∏–º –≤–∫–ª—é—á—ë–Ω–Ω—ã–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
                enabled_integrations = {}
                if integrations_config:
                    try:
                        # –ï—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞, –ø–∞—Ä—Å–∏–º JSON
                        if isinstance(integrations_config, str):
                            integrations_config = json.loads(integrations_config)
                        
                        # integrations_config –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å dict
                        if isinstance(integrations_config, dict):
                            for integration_type, config in integrations_config.items():
                                if isinstance(config, dict):
                                    enabled_integrations[integration_type] = config.get('enabled', False)
                                    logger.info(f"   üìç {integration_type}: enabled={config.get('enabled', False)}")
                        else:
                            logger.warning(f"‚ö†Ô∏è Unexpected config type for {enterprise_number}: {type(integrations_config)}")
                    except Exception as e:
                        logger.error(f"‚ùå Error parsing config for {enterprise_number}: {e}")
                
                matrix[enterprise_number] = enabled_integrations
            
            logger.info(f"üìä Loaded integration matrix for {len(matrix)} enterprises")
            return matrix
            
    except Exception as e:
        logger.error(f"‚ùå Error loading integration matrix: {e}")
        return {}

async def refresh_cache():
    """–ü–æ–ª–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞"""
    global integration_cache, cache_stats
    
    start_time = time.time()
    matrix = await load_integration_matrix()
    
    # –ê—Ç–æ–º–∞—Ä–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞
    new_cache = {}
    for enterprise_number, integrations in matrix.items():
        new_cache[enterprise_number] = CacheEntry(integrations)
    
    integration_cache = new_cache
    cache_stats["refreshes"] += 1
    cache_stats["cache_size"] = len(integration_cache)
    cache_stats["last_full_refresh"] = datetime.now().isoformat()
    
    elapsed = time.time() - start_time
    logger.info(f"üîÑ Cache refreshed: {len(integration_cache)} entries in {elapsed:.2f}s")

async def invalidate_enterprise_cache(enterprise_number: str):
    """–ò–Ω–≤–∞–ª–∏–¥–∞—Ü–∏—è –∫—ç—à–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è"""
    if enterprise_number in integration_cache:
        del integration_cache[enterprise_number]
        logger.info(f"üóëÔ∏è Cache invalidated for enterprise {enterprise_number}")

async def cleanup_expired_entries():
    """–û—á–∏—Å—Ç–∫–∞ –ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π"""
    global integration_cache, cache_stats
    
    expired_keys = [
        key for key, entry in integration_cache.items() 
        if entry.is_expired()
    ]
    
    for key in expired_keys:
        del integration_cache[key]
    
    if expired_keys:
        cache_stats["cache_size"] = len(integration_cache)
        logger.info(f"üßπ Cleaned up {len(expired_keys)} expired cache entries")

async def listen_for_invalidations():
    """–°–ª—É—à–∞–µ—Ç NOTIFY —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∏–Ω–≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫—ç—à–∞"""
    if not pg_pool:
        return
    
    try:
        async with pg_pool.acquire() as conn:
            await conn.add_listener('integration_config_changed', 
                                  lambda conn, pid, channel, payload: 
                                  asyncio.create_task(handle_invalidation_notification(payload)))
            
            logger.info("üëÇ Listening for cache invalidation notifications")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º LISTEN
            await conn.execute("LISTEN integration_config_changed")
            
            # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω—ã–º
            while True:
                await asyncio.sleep(10)
                
    except Exception as e:
        logger.error(f"‚ùå Error in invalidation listener: {e}")

async def handle_invalidation_notification(payload: str):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ–± –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    try:
        data = json.loads(payload)
        enterprise_number = data.get('enterprise_number')
        if enterprise_number:
            await invalidate_enterprise_cache(enterprise_number)
    except Exception as e:
        logger.error(f"‚ùå Error handling invalidation notification: {e}")

# API Endpoints

@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    return {
        "status": "healthy",
        "cache_size": len(integration_cache),
        "database_connected": pg_pool is not None,
        "uptime_seconds": time.time() - start_time if 'start_time' in globals() else 0
    }

@app.get("/stats")
async def get_stats():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞"""
    hit_rate = cache_stats["hits"] / max(1, cache_stats["total_requests"]) * 100
    
    return {
        **cache_stats,
        "hit_rate_percent": round(hit_rate, 2),
        "cache_entries": len(integration_cache)
    }

@app.get("/integrations/{enterprise_number}")
async def get_integrations(enterprise_number: str):
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–π –¥–ª—è –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è"""
    global cache_stats
    
    cache_stats["total_requests"] += 1
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
    if enterprise_number in integration_cache:
        entry = integration_cache[enterprise_number]
        if not entry.is_expired():
            cache_stats["hits"] += 1
            return entry.to_dict()
        else:
            # –ü—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω–∞—è –∑–∞–ø–∏—Å—å
            del integration_cache[enterprise_number]
    
    # Cache miss - –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –ë–î
    cache_stats["misses"] += 1
    matrix = await load_integration_matrix()
    
    if enterprise_number in matrix:
        entry = CacheEntry(matrix[enterprise_number])
        integration_cache[enterprise_number] = entry
        cache_stats["cache_size"] = len(integration_cache)
        return entry.to_dict()
    
    raise HTTPException(status_code=404, detail="Enterprise not found")

@app.post("/cache/invalidate/{enterprise_number}")
async def invalidate_cache(enterprise_number: str):
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω–≤–∞–ª–∏–¥–∞—Ü–∏—è –∫—ç—à–∞ –¥–ª—è –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è"""
    await invalidate_enterprise_cache(enterprise_number)
    return {"message": f"Cache invalidated for enterprise {enterprise_number}"}

@app.post("/cache/refresh")
async def force_refresh():
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤—Å–µ–≥–æ –∫—ç—à–∞"""
    await refresh_cache()
    return {"message": "Cache refreshed successfully"}

@app.get("/cache/entries")
async def get_cache_entries():
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –∑–∞–ø–∏—Å–∏ –∫—ç—à–∞ (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)"""
    return {
        enterprise: entry.to_dict() 
        for enterprise, entry in integration_cache.items()
    }

# Background tasks

async def background_refresh_task():
    """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫—ç—à–∞"""
    while True:
        try:
            # –î–∂–∏—Ç—Ç–µ—Ä –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è stampede
            jitter = random.randint(-REFRESH_JITTER_MAX, REFRESH_JITTER_MAX)
            sleep_time = REFRESH_INTERVAL_BASE + jitter
            
            await asyncio.sleep(sleep_time)
            await refresh_cache()
            
        except Exception as e:
            logger.error(f"‚ùå Error in background refresh: {e}")
            await asyncio.sleep(60)  # Retry —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É

async def background_cleanup_task():
    """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –æ—á–∏—Å—Ç–∫–∏ –ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π"""
    while True:
        try:
            await asyncio.sleep(CACHE_CLEANUP_INTERVAL)
            await cleanup_expired_entries()
        except Exception as e:
            logger.error(f"‚ùå Error in background cleanup: {e}")

# Startup event
@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ"""
    global start_time
    start_time = time.time()
    
    logger.info("üöÄ Starting Integration Cache Service")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î
    await init_database()
    
    # –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∫—ç—à–∞
    await refresh_cache()
    
    # –ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á
    asyncio.create_task(background_refresh_task())
    asyncio.create_task(background_cleanup_task())
    asyncio.create_task(listen_for_invalidations())
    
    logger.info("‚úÖ Integration Cache Service started successfully")

@app.on_event("shutdown")
async def shutdown_event():
    """–û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏"""
    if pg_pool:
        await pg_pool.close()
    logger.info("üëã Integration Cache Service stopped")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8020)
